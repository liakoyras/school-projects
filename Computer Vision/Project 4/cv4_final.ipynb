{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.layers import Activation\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 118, 118, 64)      23296     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 59, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 59, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 49, 49, 128)       991360    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 256)       3965184   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 11,405,958\n",
      "Trainable params: 11,405,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "# Add convolution and pooling layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(64, (11,11), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.Conv2D(128, (11,11), activation='relu')) \n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.Conv2D(256, (11,11), activation='relu')) \n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cofnigure paths\n",
    "import os\n",
    "base_dir = '/kaggle/input/duth-cv-2019-2020-hw-4/vehicles'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2494 images belonging to 6 classes.\n",
      "Found 311 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(128,128),\n",
    "                                                    shuffle=True)     \n",
    "# Flow validation images in batches of 20 using val_datagen generator\n",
    "validation_generator =  val_datagen.flow_from_directory(validation_dir,\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='categorical',\n",
    "                                                         target_size=(128,128)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define callback that saves the best epoch\n",
    "mcp_save = ModelCheckpoint('best_epoch.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/124 [==============================] - 20s 157ms/step - loss: 1.5740 - acc: 0.3508 - val_loss: 1.5323 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.53225, saving model to best_epoch.h5\n",
      "Epoch 2/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 1.3761 - acc: 0.4463 - val_loss: 1.1194 - val_acc: 0.4791\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.53225 to 1.11940, saving model to best_epoch.h5\n",
      "Epoch 3/100\n",
      "125/124 [==============================] - 14s 114ms/step - loss: 1.1813 - acc: 0.5545 - val_loss: 1.0256 - val_acc: 0.5691\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.11940 to 1.02555, saving model to best_epoch.h5\n",
      "Epoch 4/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 1.0962 - acc: 0.5842 - val_loss: 1.4968 - val_acc: 0.5305\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.02555\n",
      "Epoch 5/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 1.0210 - acc: 0.6151 - val_loss: 0.6145 - val_acc: 0.6013\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.02555 to 0.61446, saving model to best_epoch.h5\n",
      "Epoch 6/100\n",
      "125/124 [==============================] - 14s 114ms/step - loss: 0.9649 - acc: 0.6455 - val_loss: 0.9474 - val_acc: 0.5723\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.61446\n",
      "Epoch 7/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.9210 - acc: 0.6564 - val_loss: 1.4391 - val_acc: 0.5434\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.61446\n",
      "Epoch 8/100\n",
      "125/124 [==============================] - 14s 114ms/step - loss: 0.8710 - acc: 0.6684 - val_loss: 1.0818 - val_acc: 0.6141\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.61446\n",
      "Epoch 9/100\n",
      "125/124 [==============================] - 14s 114ms/step - loss: 0.8142 - acc: 0.6957 - val_loss: 0.6740 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.61446\n",
      "Epoch 10/100\n",
      "125/124 [==============================] - 15s 117ms/step - loss: 0.7263 - acc: 0.7358 - val_loss: 0.6772 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.61446\n",
      "Epoch 11/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.6752 - acc: 0.7502 - val_loss: 1.2026 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.61446\n",
      "Epoch 12/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.5741 - acc: 0.7907 - val_loss: 1.0092 - val_acc: 0.5820\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.61446\n",
      "Epoch 13/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.5161 - acc: 0.8208 - val_loss: 1.6778 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.61446\n",
      "Epoch 14/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.4227 - acc: 0.8569 - val_loss: 1.1384 - val_acc: 0.5949\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.61446\n",
      "Epoch 15/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.3497 - acc: 0.8805 - val_loss: 0.5242 - val_acc: 0.6463\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.61446 to 0.52415, saving model to best_epoch.h5\n",
      "Epoch 16/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.2851 - acc: 0.9034 - val_loss: 1.8014 - val_acc: 0.6334\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.52415\n",
      "Epoch 17/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.2275 - acc: 0.9282 - val_loss: 3.6983 - val_acc: 0.6334\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.52415\n",
      "Epoch 18/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.2050 - acc: 0.9290 - val_loss: 1.7903 - val_acc: 0.5820\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.52415\n",
      "Epoch 19/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.1661 - acc: 0.9451 - val_loss: 1.1385 - val_acc: 0.6270\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.52415\n",
      "Epoch 20/100\n",
      "125/124 [==============================] - 14s 115ms/step - loss: 0.1150 - acc: 0.9651 - val_loss: 0.3941 - val_acc: 0.5820\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.52415 to 0.39415, saving model to best_epoch.h5\n",
      "Epoch 21/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0983 - acc: 0.9715 - val_loss: 1.4604 - val_acc: 0.6367\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.39415\n",
      "Epoch 22/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0676 - acc: 0.9824 - val_loss: 1.0242 - val_acc: 0.6495\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.39415\n",
      "Epoch 23/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0903 - acc: 0.9727 - val_loss: 0.3297 - val_acc: 0.6399\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.39415 to 0.32965, saving model to best_epoch.h5\n",
      "Epoch 24/100\n",
      "125/124 [==============================] - 14s 114ms/step - loss: 0.0790 - acc: 0.9751 - val_loss: 0.3308 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.32965\n",
      "Epoch 25/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.0472 - acc: 0.9920 - val_loss: 1.2639 - val_acc: 0.6141\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.32965\n",
      "Epoch 26/100\n",
      "125/124 [==============================] - 14s 115ms/step - loss: 0.0469 - acc: 0.9884 - val_loss: 2.3100 - val_acc: 0.6495\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.32965\n",
      "Epoch 27/100\n",
      "125/124 [==============================] - 14s 115ms/step - loss: 0.0404 - acc: 0.9884 - val_loss: 4.1686 - val_acc: 0.6174\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.32965\n",
      "Epoch 28/100\n",
      "125/124 [==============================] - 14s 114ms/step - loss: 0.0346 - acc: 0.9924 - val_loss: 4.0258 - val_acc: 0.6334\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.32965\n",
      "Epoch 29/100\n",
      "125/124 [==============================] - 14s 115ms/step - loss: 0.0394 - acc: 0.9880 - val_loss: 1.6068 - val_acc: 0.5981\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.32965\n",
      "Epoch 30/100\n",
      "125/124 [==============================] - 14s 114ms/step - loss: 0.1067 - acc: 0.9671 - val_loss: 0.4600 - val_acc: 0.5884\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.32965\n",
      "Epoch 31/100\n",
      "125/124 [==============================] - 15s 121ms/step - loss: 0.0363 - acc: 0.9908 - val_loss: 3.4163 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.32965\n",
      "Epoch 32/100\n",
      "125/124 [==============================] - 14s 114ms/step - loss: 0.0268 - acc: 0.9928 - val_loss: 1.5222 - val_acc: 0.6270\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.32965\n",
      "Epoch 33/100\n",
      "125/124 [==============================] - 15s 117ms/step - loss: 0.0192 - acc: 0.9964 - val_loss: 4.2845 - val_acc: 0.6174\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.32965\n",
      "Epoch 34/100\n",
      "125/124 [==============================] - 14s 114ms/step - loss: 0.0167 - acc: 0.9968 - val_loss: 1.7418 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.32965\n",
      "Epoch 35/100\n",
      "125/124 [==============================] - 14s 114ms/step - loss: 0.0075 - acc: 0.9992 - val_loss: 0.1731 - val_acc: 0.6174\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.32965 to 0.17315, saving model to best_epoch.h5\n",
      "Epoch 36/100\n",
      "125/124 [==============================] - 14s 114ms/step - loss: 0.0104 - acc: 0.9976 - val_loss: 1.5858 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.17315\n",
      "Epoch 37/100\n",
      "125/124 [==============================] - 14s 115ms/step - loss: 0.0188 - acc: 0.9952 - val_loss: 2.7355 - val_acc: 0.5852\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.17315\n",
      "Epoch 38/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0712 - acc: 0.9771 - val_loss: 1.1390 - val_acc: 0.6270\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.17315\n",
      "Epoch 39/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0379 - acc: 0.9896 - val_loss: 5.2551 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.17315\n",
      "Epoch 40/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0371 - acc: 0.9896 - val_loss: 4.4836 - val_acc: 0.6013\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.17315\n",
      "Epoch 41/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0272 - acc: 0.9920 - val_loss: 2.7895 - val_acc: 0.6302\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.17315\n",
      "Epoch 42/100\n",
      "125/124 [==============================] - 14s 115ms/step - loss: 0.0360 - acc: 0.9900 - val_loss: 0.7719 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.17315\n",
      "Epoch 43/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.0105 - acc: 0.9988 - val_loss: 1.4221 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.17315\n",
      "Epoch 44/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.0118 - acc: 0.9972 - val_loss: 5.6646 - val_acc: 0.5820\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.17315\n",
      "Epoch 45/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0653 - acc: 0.9783 - val_loss: 2.8286 - val_acc: 0.6045\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.17315\n",
      "Epoch 46/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0458 - acc: 0.9864 - val_loss: 0.8736 - val_acc: 0.5916\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.17315\n",
      "Epoch 47/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0231 - acc: 0.9944 - val_loss: 1.1628 - val_acc: 0.6013\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.17315\n",
      "Epoch 48/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0182 - acc: 0.9944 - val_loss: 0.6978 - val_acc: 0.6077\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.17315\n",
      "Epoch 49/100\n",
      "125/124 [==============================] - 14s 114ms/step - loss: 0.0125 - acc: 0.9976 - val_loss: 1.9533 - val_acc: 0.6077\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.17315\n",
      "Epoch 50/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0639 - acc: 0.9779 - val_loss: 1.6311 - val_acc: 0.5981\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.17315\n",
      "Epoch 51/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0224 - acc: 0.9928 - val_loss: 1.9544 - val_acc: 0.6334\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.17315\n",
      "Epoch 52/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0097 - acc: 0.9984 - val_loss: 1.3355 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.17315\n",
      "Epoch 53/100\n",
      "125/124 [==============================] - 15s 117ms/step - loss: 0.0076 - acc: 0.9988 - val_loss: 4.6071 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.17315\n",
      "Epoch 54/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0050 - acc: 0.9992 - val_loss: 2.4658 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.17315\n",
      "Epoch 55/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 1.2554 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.17315\n",
      "Epoch 56/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 3.5744 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.17315\n",
      "Epoch 57/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 3.7138 - val_acc: 0.5981\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.17315\n",
      "Epoch 58/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0272 - acc: 0.9912 - val_loss: 6.0014 - val_acc: 0.6013\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.17315\n",
      "Epoch 59/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0876 - acc: 0.9719 - val_loss: 3.1282 - val_acc: 0.5852\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.17315\n",
      "Epoch 60/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 4.1687 - val_acc: 0.5402\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.17315\n",
      "Epoch 70/100\n",
      "125/124 [==============================] - 14s 110ms/step - loss: 0.0154 - acc: 0.9952 - val_loss: 3.2334 - val_acc: 0.5981\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.17315\n",
      "Epoch 71/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.0060 - acc: 0.9992 - val_loss: 1.0404 - val_acc: 0.6270\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.17315\n",
      "Epoch 72/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0069 - acc: 0.9988 - val_loss: 4.6739 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.17315\n",
      "Epoch 73/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 6.7383 - val_acc: 0.6013\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.17315\n",
      "Epoch 74/100\n",
      "125/124 [==============================] - 14s 115ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 4.2409 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.17315\n",
      "Epoch 75/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0383 - acc: 0.9884 - val_loss: 1.9473 - val_acc: 0.5691\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.17315\n",
      "Epoch 76/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0713 - acc: 0.9775 - val_loss: 0.9431 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.17315\n",
      "Epoch 77/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.0162 - acc: 0.9944 - val_loss: 1.2896 - val_acc: 0.6270\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.17315\n",
      "Epoch 78/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0373 - acc: 0.9900 - val_loss: 1.5497 - val_acc: 0.5884\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.17315\n",
      "Epoch 79/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0177 - acc: 0.9956 - val_loss: 0.8870 - val_acc: 0.6045\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.17315\n",
      "Epoch 80/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0095 - acc: 0.9976 - val_loss: 1.7503 - val_acc: 0.5949\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.17315\n",
      "Epoch 81/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0067 - acc: 0.9976 - val_loss: 1.9249 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.17315\n",
      "Epoch 82/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0039 - acc: 0.9996 - val_loss: 3.1801 - val_acc: 0.6045\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.17315\n",
      "Epoch 83/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.0016 - acc: 0.9992 - val_loss: 3.4491 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.17315\n",
      "Epoch 84/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0015 - acc: 0.9992 - val_loss: 0.9365 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.17315\n",
      "Epoch 85/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 9.1808e-04 - acc: 0.9996 - val_loss: 2.5515 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.17315\n",
      "Epoch 86/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 2.2164 - val_acc: 0.6013\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.17315\n",
      "Epoch 87/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0071 - acc: 0.9984 - val_loss: 2.2210 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.17315\n",
      "Epoch 88/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0299 - acc: 0.9920 - val_loss: 3.6142 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.17315\n",
      "Epoch 89/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.0463 - acc: 0.9864 - val_loss: 5.6483 - val_acc: 0.5659\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.17315\n",
      "Epoch 90/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0569 - acc: 0.9808 - val_loss: 0.7342 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.17315\n",
      "Epoch 91/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0220 - acc: 0.9928 - val_loss: 2.2886 - val_acc: 0.6013\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.17315\n",
      "Epoch 92/100\n",
      "125/124 [==============================] - 14s 110ms/step - loss: 0.0096 - acc: 0.9980 - val_loss: 0.6249 - val_acc: 0.5691\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.17315\n",
      "Epoch 93/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0172 - acc: 0.9948 - val_loss: 4.9926 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.17315\n",
      "Epoch 94/100\n",
      "125/124 [==============================] - 14s 113ms/step - loss: 0.0283 - acc: 0.9924 - val_loss: 2.0047 - val_acc: 0.5916\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.17315\n",
      "Epoch 95/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0036 - acc: 0.9996 - val_loss: 2.0559 - val_acc: 0.5949\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.17315\n",
      "Epoch 96/100\n",
      "125/124 [==============================] - 15s 116ms/step - loss: 0.0027 - acc: 0.9996 - val_loss: 4.0827 - val_acc: 0.6141\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.17315\n",
      "Epoch 97/100\n",
      "125/124 [==============================] - 14s 111ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 6.2330 - val_acc: 0.5820\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.17315\n",
      "Epoch 98/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 3.5013 - val_acc: 0.6109\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.17315\n",
      "Epoch 99/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0026 - acc: 0.9996 - val_loss: 2.6623 - val_acc: 0.6174\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.17315\n",
      "Epoch 100/100\n",
      "125/124 [==============================] - 14s 112ms/step - loss: 0.0022 - acc: 0.9992 - val_loss: 1.7067 - val_acc: 0.6141\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.17315\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=5e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      callbacks=[mcp_save],\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "import csv\n",
    "\n",
    "model = tf.keras.models.load_model('/kaggle/working/best_epoch.h5')\n",
    "rowlist = [['Id', 'Category']]\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/duth-cv-2019-2020-hw-4/vehicles/test'):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)\n",
    "        img = image.load_img(path, target_size=(128, 128), grayscale=False, interpolation='bilinear')\n",
    "        \n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        classes_pred = model.predict(x)\n",
    "        cls_pred = np.argmax(classes_pred)\n",
    "        rowlist.append([filename, cls_pred])\n",
    "        with open('output.csv', 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(rowlist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
